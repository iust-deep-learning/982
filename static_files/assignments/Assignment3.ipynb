{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlK9Zp9RGLsY",
        "colab_type": "text"
      },
      "source": [
        "# Assignment #3 - Computer Vision\n",
        "\n",
        "\n",
        "Deep Learning / Spring 1399, Iran University of Science and Technology\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsqaKAWkGd8F",
        "colab_type": "text"
      },
      "source": [
        "**Please pay attention to these notes:**\n",
        "<br><br>\n",
        "\n",
        "\n",
        "- **Assignment Due: ** 1399/3/7 23:59:00\n",
        "- If you need any additional information, please review the assignment page on the course website.\n",
        "- The items you need to answer are highlighted in red and the coding parts you need to implement are denoted by:\n",
        "```\n",
        "########################################\n",
        "#     Put your implementation here     #\n",
        "########################################\n",
        "```\n",
        "- We always recommend co-operation and discussion in groups for assignments. However, each student has to finish all the questions by him/herself. If our matching system identifies any sort of copying, you'll be responsible for consequences. So, please mention his/her name if you have a team-mate.\n",
        "- Students who audit this course should submit their assignments like other students to be qualified for attending the rest of the sessions.\n",
        "- Finding any sort of copying will zero down that assignment grade and also will be counted as two negative assignment for your final score.\n",
        "- When you are ready to submit, please follow the instructions at the end of this notebook.\n",
        "- If you have any questions about this assignment, feel free to drop us a line. You may also post your questions on the course Forum page.\n",
        "- You must run this notebook on Google Colab platform, it depends on Google Colab VM for some of the depencecies.\n",
        "- **Before starting to work on the assignment Please fill your name in the next section *AND Remember to RUN the cell.* **\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "Course Forum: [https://groups.google.com/forum/#!forum/dl982/](https://groups.google.com/forum/#!forum/dl982/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-EaKTaxGpzn",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3CNCKmFGq-c",
        "colab_type": "text"
      },
      "source": [
        "Fill your information here & run the cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCiLfTooGuIW",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Enter your information & \"RUN the cell!!\"\n",
        "student_id =  0#@param {type:\"integer\"}\n",
        "student_name = \"\" #@param {type:\"string\"}\n",
        "Your_Github_account_Email = \"\" #@param {type:\"string\"}\n",
        "\n",
        "print(\"your student id:\", student_id)\n",
        "print(\"your name:\", student_name)\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "ASSIGNMENT_PATH = Path('asg03')\n",
        "ASSIGNMENT_PATH.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8R9A5ns2Uz_",
        "colab_type": "text"
      },
      "source": [
        "In this assignment we will learn how to perform *image classification* using Machine learning algorithm and deep computer vision with special layer called a **convolutional neural network** and improve the performance of our model with power of transfer learning.\n",
        "\n",
        "The goal of our methods will be to classify and detect images. We will be using image data as our features and a label for those images as our label or output.\n",
        "\n",
        "We already know how neural networks work so we can skip through the basics and move right into explaining our different approaches.\n",
        "\n",
        "The major differences we are about to see in these types of neural networks are the layers that make them up.\n",
        "\n",
        "The using data has ten classes of images: `[airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck]` \n",
        "\n",
        "So briefly, this assignment consists of five subsections:\n",
        "* Reading & Preparing Image Data \n",
        "* Features Extraction for classical methods\n",
        "* SVM classification\n",
        "* Using CNN \n",
        "* Advantages of Transfer Learning\n",
        "* Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sOYBbN4LhqY",
        "colab_type": "text"
      },
      "source": [
        "# Loading and Preprocessing Images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLkuG4rFKFun",
        "colab_type": "text"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnjQp-tZeuaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imageio import imsave\n",
        "from IPython.display import clear_output\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import os, sys, tarfile, errno\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request as urllib \n",
        "import scipy.io as sio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5_gqcNX4uQF",
        "colab_type": "text"
      },
      "source": [
        "Before running the next cell, you should take the data by following this instruction.\n",
        "\n",
        "\n",
        "For adding the data into your drive, follow the steps: \n",
        "* First, tap on the link below: \n",
        "\n",
        "    https://drive.google.com/drive/folders/1d79qDmudm-Et2vX_OP-DD6l35py-0yCH?usp=sharing\n",
        "\n",
        "* Now you can see `IMAGES` folder, the shared folder in your drive. `Right-Click` on it and then tap on `Add shortcut to Drive` to save it.\n",
        "\n",
        "* If you have any problems with the data path in the next cells, you should check the location of saving data. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRtLjYBrEVLF",
        "colab_type": "text"
      },
      "source": [
        "Now you have to mount your drive on this notebook to access the data. After running the next cell, you can see your google drive directory in **Files**, the left side of this page."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G_jgwbh0nWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YklJxVQ7s1JO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path to the binary train file with image data\n",
        "DATA_TRAIN_PATH = './drive/My Drive/IMAGES/train_X.bin'\n",
        "\n",
        "# path to the binary test file with image data\n",
        "DATA_TEST_PATH = './drive/My Drive/IMAGES/test_X.bin'\n",
        "\n",
        "# path to the binary train file with labels\n",
        "LABEL_TRAIN_PATH = './drive/My Drive/IMAGES/train_y.bin'\n",
        "\n",
        "# path to the binary test file with labels\n",
        "LABEL_TEST_PATH = './drive/My Drive/IMAGES/test_y.bin'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8i6456BZNXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image shape \n",
        "HEIGHT = 96\n",
        "WIDTH = 96\n",
        "DEPTH = 3\n",
        "\n",
        "# size of a single image in bytes\n",
        "SIZE = HEIGHT * WIDTH * DEPTH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf6epNo22heC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "For checking the various functions, you must read a single image. You can use numpy **fromfile** function.\n",
        "Then make the image matrix : 3x96x96 \n",
        "\n",
        "some hints:\n",
        "\n",
        "1- The data is in binary format and you should read it in uint8 chunks - do not forget to make an image matrix\n",
        "\n",
        "2- Transpose the image into a standard format to be readable by, for example, `matplotlib.pyplot` \n",
        "\n",
        "3- All images are in the same size, so do not worry about them "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYs8wFI8mgK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_single_image(image_file):\n",
        "    \"\"\"\n",
        "    input: the open file containing the images\n",
        "    return: a single image\n",
        "    \"\"\"\n",
        "    ########################################\n",
        "    #     Put your implementation here     #\n",
        "    ########################################\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzSVVf-p2sHT",
        "colab_type": "text"
      },
      "source": [
        "Now write a function to display an image. This function should take the image to be plotted in a 3-D matrix format. You can use `matplotlib.pyplot`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDL2aoVhnqSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image(image):\n",
        "    \"\"\"\n",
        "    input: the image to be plotted in a 3-D matrix format\n",
        "    return: None\n",
        "    \"\"\"\n",
        "    ########################################\n",
        "    #     Put your implementation here     #\n",
        "    ########################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXpi0WaEXdmr",
        "colab_type": "text"
      },
      "source": [
        "Time to check your funcs! if everything is alright, you will see a cute bird by executing the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG_HWprinbQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(DATA_TRAIN_PATH) as f:\n",
        "    image = read_single_image(f)\n",
        "    plot_image(image)\n",
        "assert image.shape == (96, 96, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCJkyLXyZqiN",
        "colab_type": "text"
      },
      "source": [
        "* You probably noticed that we force the data into 3x96x96 chunks, since the images are stored in \"column-major order\". It means that the first 96x96 values are the **red channel**, the next 96x96 are **green**, and the last are **blue**.\n",
        "* Now write a function to read all images instead of a sinle image like `read_single_image`. You should use `reshape` and `transpose` methods in this function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNeolmtun_er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_all_images(path_to_data):\n",
        "    \"\"\"\n",
        "    input: the file containing the binary images \n",
        "    return: an array containing all the images\n",
        "    \"\"\"\n",
        "    ########################################\n",
        "    #     Put your implementation here     #\n",
        "    ########################################\n",
        "\n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGgJhP3g3EbO",
        "colab_type": "text"
      },
      "source": [
        "Test to check if the **whole** dataset is read correctly:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L8n3cwRoef0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = read_all_images(DATA_TRAIN_PATH)\n",
        "print(images.shape)\n",
        "assert images.shape == (5000, HEIGHT, WIDTH, DEPTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "petRs-6Zuy7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_test = read_all_images(DATA_TEST_PATH)\n",
        "print(images_test.shape)\n",
        "assert images_test.shape == (8000, HEIGHT, WIDTH, DEPTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6TC9gS43d_L",
        "colab_type": "text"
      },
      "source": [
        "* It's time to get the identities. Write a function to read all images **labels**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp51kjOCrSq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_labels(path_to_labels):\n",
        "    \"\"\"\n",
        "    input: path to the binary file containing labels \n",
        "    return: an array containing the labels\n",
        "    \"\"\"\n",
        "    ########################################\n",
        "    #     Put your implementation here     #\n",
        "    ########################################\n",
        "    \n",
        "    return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-LFgKsq3YD1",
        "colab_type": "text"
      },
      "source": [
        "read all **training** labels \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmQJ3_ZGuaCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read all train labels \n",
        "labels = read_labels(LABEL_TRAIN_PATH)\n",
        "labels = labels.reshape(5000,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miK1AOTY3RSX",
        "colab_type": "text"
      },
      "source": [
        "read all **testing** labels \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzdAAnykvRhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_test = read_labels(LABEL_TEST_PATH)\n",
        "labels_test = labels_test.reshape(8000,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCJy_PHG7t9C",
        "colab_type": "text"
      },
      "source": [
        "Here we want to save the images separately in their class folders. Solving this part gives you an insight of preparing and using images data in professional classification tasks. So it might be helpful in the future.\n",
        "* Save all images to the 'image' directory + 'label' name. \n",
        "* Images should be in png format \n",
        "* Use the defined parameters, **Images** and **labels** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfKi5ZiTrSn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(images, labels):\n",
        "    print(\"Saving images to disk\")\n",
        "    i = 0\n",
        "    for image in images:\n",
        "        label = labels[i]\n",
        "        directory = './image/' + str(label) + '/'\n",
        "        try:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "        except OSError as exc:\n",
        "            if exc.errno == errno.EEXIST:\n",
        "                pass\n",
        "        filename = directory + str(i)\n",
        "        print(filename)\n",
        "        imsave(\"%s.png\" % filename, image, format=\"png\")\n",
        "        i = i+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf45t4-SsKIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save images\n",
        "save_images(images, labels)\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0296KcF3xq2",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing and Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2bPPKt-qlRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "%matplotlib inline\n",
        "import string\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "from pickle import load\n",
        "from keras.preprocessing import image as IMG\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5Y9YFMuvE6U",
        "colab_type": "text"
      },
      "source": [
        "Pre-processing images is most important part while making programs related to image or optical recognition. When we use machine learning or learning networks to recognize images, the image must be in same format for which we have trained the network or our ML algorithm. So pre-processing is very much important to make images more precise and accurate. Steps in pre-processing may be resizing, cropping, changing hue, making black and white etc. In the next cell we want to do some pre-processing on an image. \n",
        "\n",
        "As you noticed, we imported `image` from `keras.preprocessing` as **IMG** in the previous cell. For converting images to numpy array, this module will be usable. Also we want to use some functions of the keras pretrained networks called **Inception-v3** for using pre-process on the inputs.\n",
        "\n",
        "So briefly, you should implement the following steps to complete the next cell:\n",
        "- Convert image instance to numpy array (check **IMG**)\n",
        "- Check the *Inception-V3* input dimensions \n",
        "- Use defined pre-process function of *Inception-v3*\n",
        "\n",
        "Hint: https://keras.io/applications/\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlZrWvNOVL05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(img):\n",
        "  \n",
        "  ########################################\n",
        "  #     Put your implementation here     #\n",
        "  ########################################\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqTIDXPpgGRJ",
        "colab_type": "text"
      },
      "source": [
        " For checking the performance of our `preprocess_image` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n76PVgn4V0rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = preprocess_image(image) # image = a bird\n",
        "newimg = img.reshape(96,96,3)\n",
        "plt.imshow(newimg)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6BCSjmQxY01",
        "colab_type": "text"
      },
      "source": [
        "Please describe the preprocess function you used in the previous cells. \n",
        "\n",
        "$\\color{red}{\\text{Write Your Answer Here}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtwpQ-7S36TH",
        "colab_type": "text"
      },
      "source": [
        "Let's see how to convert RGB image to grayscale with the use of numpy library: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkYCDr9fq6n0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rgb2gray(rgb):\n",
        "  \"\"\"\n",
        "      input : RGB image\n",
        "      Returns: grayscale image\n",
        "  \"\"\"\n",
        "  return np.dot(rgb[...,:3], [0.299, 0.587, 0.144])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Doavgf0mmV39",
        "colab_type": "text"
      },
      "source": [
        "* Make a list of images that each one is pre-processed, grayscaled and flattened. Use defined **images** array here, obtained from `read_all_images`. It's essential to use our implemented functions: `(preprocess_image, rgb2gray)` \n",
        "* Then convert the list to an array which named `new_image_list`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn-W0n_qqt-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################\n",
        "#     Put your implementation here     #\n",
        "########################################\n",
        "new_image_list.shape\n",
        "assert new_image_list.shape == (5000, 9216)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWpOBw0xoPBl",
        "colab_type": "text"
      },
      "source": [
        "Do all of the above implementations for the test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIkcvcgikR6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################\n",
        "#     Put your implementation here     #\n",
        "########################################\n",
        "new_image_test_list.shape\n",
        "assert new_image_test_list.shape == (8000, 9216)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGcyBF8uo5VG",
        "colab_type": "text"
      },
      "source": [
        "If you completed all the past cells well, you can see the preprocessed images with their class labels correctly in the below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP-zex0GOQry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (7,9)\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.imshow(new_image_list[4*i].reshape(96,96), interpolation='none', cmap = 'gray')\n",
        "  plt.title(\"Class {}\".format(labels[4*i][-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiYcZEcT8r6d",
        "colab_type": "text"
      },
      "source": [
        "## PCA\n",
        "Principal components analysis is essentially just a coordinate transformation. The original data are plotted on an X-axis and a Y-axis. For two-dimensional data, PCA seeks to rotate these two axes so that the new axis X’ lies along the direction of maximum variation in the data. PCA requires that the axes be perpendicular, so in two dimensions the choice of X’ will determine Y’. You obtain the transformed data by reading the x and y values off this new set of axes, X’ and Y’. For more than two dimensions, the first axis is in the direction of most variation; the second, in direction of the next-most variation; and so on.\n",
        "<p align=\"center\"><img src=\"https://github.com/iust-deep-learning/982/raw/master/static_files/assignments/asg03_assets/1_QA.png\" />   \n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycAi2YEBpF5j",
        "colab_type": "text"
      },
      "source": [
        "Now we have an array of pre-processed and grayscaled images and we want to extract features with PCA method.\n",
        "\n",
        "* This link can help for PCA understanding https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_iris.html\n",
        "\n",
        "* We use `StandardScaler` in this process. This link can help for StandardScaler understanding https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-OlAEPIaCYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import sklearn.metrics as skm\n",
        "from IPython.display import SVG\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UliNVRDqrKXB",
        "colab_type": "text"
      },
      "source": [
        "Use PCA to extract features for both train and test data. \n",
        "\n",
        "Check the **Sklearn** for performing `PCA` on your data and investigate what will happen if we use a value lower than 1 as an input of PCA? How do you get the most valuable features with the help of PCA? How do you obtain the sufficient number of most important features? Also explain the `StandardScaler` functionality!\n",
        "\n",
        "$\\color{red}{\\text{Write Your Answer Here}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWZHVTXFJxUL",
        "colab_type": "text"
      },
      "source": [
        "Note: Please be patient, the next part may take a few minutes to execute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be7uJKqaZvxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(new_image_list)\n",
        "features_scaler = scaler.transform(new_image_list)\n",
        "features_test_scaler = scaler.transform(new_image_test_list)\n",
        "\"\"\"\n",
        "  input: features_scaler and features_test_scaler\n",
        "  output: features_pca and features_test_pca\n",
        "\"\"\"\n",
        "########################################\n",
        "#     Put your implementation here     #\n",
        "########################################\n",
        "print('After using PCA on the dataset, shape: ', features_pca.shape)\n",
        "print('After using PCA on the test set, shape: ', features_test_pca.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6pnnjlN9-Vz",
        "colab_type": "text"
      },
      "source": [
        "Let's see the effect of PCA on an image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQOve43JZ7WP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = new_image_list[200]\n",
        "sample.shape = (96,96)\n",
        "\n",
        "a = plt.subplot(1,2,1)\n",
        "a.set_title('Original Image')\n",
        "plt.imshow(sample, cmap = plt.cm.gray_r)\n",
        "\n",
        "sample = pca.inverse_transform(features_pca[200])\n",
        "sample.shape = (96,96)\n",
        "\n",
        "b = plt.subplot(1,2,2)\n",
        "b.set_title(\"Reduced after PCA\")\n",
        "plt.imshow(sample, cmap = plt.cm.gray_r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsZcVHT6MBui",
        "colab_type": "text"
      },
      "source": [
        "# Image Classification with SVM "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbsq7zLo5jFp",
        "colab_type": "text"
      },
      "source": [
        "A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. In two dimentional space this hyperplane is a line dividing a plane in two parts where in each class lay in either side.\n",
        "\n",
        "Suppose you are given plot of two label classes on graph as shown in image (A). Can you decide a separating line for the classes?\n",
        "<p align=\"center\"><img src=\"https://github.com/iust-deep-learning/982/raw/master/static_files/assignments/asg03_assets/1_Bp.png\"/> <center><figcaption>(A)</figcaption>  </center>  \n",
        "</p>\n",
        "\n",
        "You might have come up with something similar to following image (image B). It fairly separates the two classes. Any point that is left of line falls into black circle class and on right falls into blue square class. Separation of classes, that’s what SVM does. It finds out a line/ hyper-plane (in multidimensional space that separate outs classes).\n",
        "\n",
        "<p align=\"center\"><img src=\"https://github.com/iust-deep-learning/982/raw/master/static_files/assignments/asg03_assets/1_Sg.png\" /> <center><figcaption>(B)</figcaption>  </center>\n",
        "</p>\n",
        "\n",
        "## Making it a Bit complex…\n",
        "\n",
        "So far so good. Now consider what if we had data as shown in image below? Clearly, there is no line that can separate the two classes in this x-y plane. So what do we do? \n",
        "\n",
        "We apply transformation and add one more dimension as we call it z-axis. Lets assume value of points on z plane, *w = x² + y²*. In this case we can manipulate it as distance of point from z-origin. Now if we plot in z-axis, a clear separation is visible and a line can be drawn.\n",
        "\n",
        "<p align=\"right\"><img src=\"https://github.com/iust-deep-learning/982/raw/master/static_files/assignments/asg03_assets/1_C3.png\" />   \n",
        "</p><p align=\"center\">Can you draw a separating line in this plane?</p>\n",
        "\n",
        "<p align=\"right\"><img src=\"https://github.com/iust-deep-learning/982/raw/master/static_files/assignments/asg03_assets/1_FL.png\" />   \n",
        "</p>\n",
        "\n",
        "<p align=\"center\">plot of z-y axis. A separation can be made here.</p>\n",
        "\n",
        "When we transform back this line to original plane, it maps to circular boundary as shown in the following image. These transformations are called kernels.\n",
        "\n",
        "<p align=\"right\"><img src=\"https://github.com/iust-deep-learning/982/raw/master/static_files/assignments/asg03_assets/1_NN.png\" />  </p> \n",
        "\n",
        "<p align = \"center\">Transforming back to x-y plane, a line transforms to circle.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH2xRsac9obw",
        "colab_type": "text"
      },
      "source": [
        "* Use **SVM** with name `classifierWithPCA` to classify images\n",
        "* Train SVM on `features_pca` \n",
        "* This link may help you: https://scikit-learn.org/stable/modules/svm.html\n",
        "\n",
        "* Test different parameters like `kernel` for best result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns9vPC6uD0Lj",
        "colab_type": "text"
      },
      "source": [
        "Can you offer a way to help you find the best parameters of your classifier model?\n",
        "\n",
        "\n",
        "$\\color{red}{\\text{Write Your Answer Here}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv4uhBleqInL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train a SVM on your data\n",
        "########################################\n",
        "#     Put your implementation here     #\n",
        "########################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91mUxyrgshx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "algo_score = classifierWithPCA.score(features_test_pca, labels_test)\n",
        "print(algo_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcM89j9B5ZZE",
        "colab_type": "text"
      },
      "source": [
        "What does `classifierWithPCA.score` return? \n",
        "\n",
        "$\\color{red}{\\text{Write Your Answer Here}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHFP6T796cUR",
        "colab_type": "text"
      },
      "source": [
        "Get the **accuracy** of your model  and show the classification report (`precision, recall, f1-score, support`)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IO4boi4sj9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################\n",
        "#     Put your implementation here     #\n",
        "########################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SNCcqpxA2k6",
        "colab_type": "text"
      },
      "source": [
        "As you noticed, the performance of the model is weak. Why is the accuracy so low? Explain it.\n",
        "\n",
        "$\\color{red}{\\text{Write Your Answer Here}}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN7Tc3Y9SQsG",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Network "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV1lnFFFCUrX",
        "colab_type": "text"
      },
      "source": [
        "Now it is time to create our first convnet! This part is for the purpose of getting familiar with CNN architectures. After making the model, we will talk about how to improve its performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EANibQdNGyG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import random\n",
        "import time\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer, Dense, Activation, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Dense, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras import layers, models, optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl-YYHkQHPR5",
        "colab_type": "text"
      },
      "source": [
        "Let's Normalize pixel values to be between 0 and 1. This will help our model converge to lower loss.\n",
        "\n",
        "We also change labels values to be in the range of 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McD9TjgHukvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, images_test = images / 255.0, images_test / 255.0\n",
        "labels, labels_test = labels-1, labels_test-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHqKEMNSIP3n",
        "colab_type": "text"
      },
      "source": [
        "Checking dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhKvLr5qunTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['airplane', 'bird', 'car', 'cat', 'deer',\n",
        "               'dog', 'horse', 'monkey', 'ship', 'truck']\n",
        "plt.rcParams['figure.figsize'] = (7,9)\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[labels[i][0]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzjzjw73C6pG",
        "colab_type": "text"
      },
      "source": [
        "## CNN Architecture\n",
        "A common architecture for a CNN is a stack of **Conv2D** and **MaxPooling2D** layers followed by a few denesly connected layers. The idea is that the stack of convolutional and maxPooling layers extract the features from the image. Then these features are flattened and fed to densly connected layers that determine the class of an image based on the presence of features.\n",
        "\n",
        "We will start by building the **Convolutional Base**. Also using other layers like **Dropout** or **BatchNormalization** for improving the performance is optional.\n",
        "\n",
        "After adding some **Conv2D** layers, you should notice that the depth of our image increases but the spacial dimensions reduce drastically. The output of Convolutional layers are our extracted features. Then we need to take these extracted features and add a way to classify them. This is why we add the **Flatten** and **Dense** layers to our model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_40VtSeFPZE",
        "colab_type": "text"
      },
      "source": [
        "Note: Please try to make a Simple CNN in this part with low complexity. If the number of trainable parameters are large, you may face with a \"session crashed\" message."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK2Fd3C8hMM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Simple_CNN_Model():\n",
        "  model = models.Sequential()\n",
        "  ########################################\n",
        "  #     Put your implementation here     #\n",
        "  ########################################\n",
        "  model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb7x-n38FU7q",
        "colab_type": "text"
      },
      "source": [
        "Visualize the training and evaluate the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-ab35kO_YoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_loss_and_acc(history):\n",
        "  history_dict = history.history\n",
        "  loss_values = history_dict['loss']\n",
        "  val_loss_values = history_dict['val_loss']\n",
        "  acc = history_dict['accuracy']\n",
        "\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "\n",
        "  f = plt.figure(figsize=(10,3))\n",
        "\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "  plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  acc_values = history_dict['accuracy']\n",
        "  val_acc = history_dict['val_accuracy']\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abv_mc8OFdBh",
        "colab_type": "text"
      },
      "source": [
        "Train the Simple_CNN_Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELuDxkHb8-K6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard = TensorBoard(log_dir=f\"logs/{time.time()}\", histogram_freq=1)\n",
        "CnnModel = Simple_CNN_Model()\n",
        "CnnModel.summary()\n",
        "\n",
        "CNN_Model_history = CnnModel.fit(\n",
        "    images, labels,\n",
        "    batch_size=64,\n",
        "    epochs=8,\n",
        "    validation_data=(images_test, labels_test),\n",
        "    shuffle=True,\n",
        "    callbacks=[tensorboard])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JSxHo6eFmPr",
        "colab_type": "text"
      },
      "source": [
        "It's time to call the visualization function and investigate the procedure of training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ckw9PHSB-9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_loss_and_acc(CNN_Model_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPpRjYxSHG0Q",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dxxxyEKEKZK",
        "colab_type": "text"
      },
      "source": [
        "Let's check the trained model to predict labels. We can determine how well the model performed by looking at it's prediction on the test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr8utihbHYeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = CnnModel.predict(images_test)\n",
        "\n",
        "ROWS = 5\n",
        "COLUMNS = 5\n",
        "fig, ax = plt.subplots(ROWS,COLUMNS, figsize=(18,18))\n",
        "for row in range(ROWS):\n",
        "    for column in range(COLUMNS):\n",
        "        imgIndex = random.randint(0, len(images_test))\n",
        "        image = images_test[imgIndex]\n",
        "        image = image.reshape(96,96,3)\n",
        "        ax[row,column].imshow(image,cmap=plt.cm.binary)\n",
        "        ax[row, column].set_title(class_names[np.argmax(predictions[imgIndex])], fontSize=10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5uzqKqDHYIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "algo_score = CnnModel.evaluate(images_test, labels_test)[1]\n",
        "print(algo_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYJRKimcE9m6",
        "colab_type": "text"
      },
      "source": [
        "You should be getting an accuracy of about 55%. This isn't bad for a simple model like this, but we'll dive into some better approaches for computer vision below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pbRe5hMgDPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remember to run this cell after each time you update the model, \n",
        "# this is a deliverable item of your assignemnt\n",
        "CnnModel.save(str(ASSIGNMENT_PATH / 'Animals_Image_classification.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY6O9MEfKKBV",
        "colab_type": "text"
      },
      "source": [
        "## Using Pretrained Models\n",
        "The pre-trained models are trained on very large scale image classification problems. The convolutional layers act as feature extractor and the fully connected layers act as Classifiers. Since these models are very large and have seen a huge number of images, they tend to learn very good, discriminative features. We can either use the convolutional layers merely as a feature extractor or we can tweak the already trained convolutional layers to suit our problem at hand. The former approach is known as Transfer Learning and the latter as Fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPZvjQzenmSl",
        "colab_type": "text"
      },
      "source": [
        "First of all for proving the power of these pretrained networks, let's check the ability of classification in one of them: **InceptionV3**\n",
        "\n",
        "We just pass an image to the network and it will show us the probable classes for it. it's so fun!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP4gRIfNnkT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image as IMG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KD3lVREssLe",
        "colab_type": "text"
      },
      "source": [
        "In this part you need to implement a function which reads an image as an input and performs some changes on it to be ready for prediction by **inceptionv3**. Because of necessities, it's no problem to import some modules and use them in your implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL28v1vzpFP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = InceptionV3(weights='imagenet')\n",
        "\n",
        "def pred(img):\n",
        "    ########################################\n",
        "    #     Put your implementation here     #\n",
        "    ########################################\n",
        "\n",
        "def display_img(img):\n",
        "    plt.figure(figsize = (3,3))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "display_img(images[10])\n",
        "pred(images[10])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1LzazBwnO4q",
        "colab_type": "text"
      },
      "source": [
        "But we want to use the network as a feature extractor. In this approach we create the base model from the pre-trained convnets. Keras provides a set of pre-trained networks, use this [link](https://keras.io/applications/) and take a look at them. The model we are going to use as the convolutional base for our model is the **VGG19**. \n",
        "\n",
        "We are going to use this model but only its convolutional base. So, when we load it, we'll specify that we don't want to load the top (classification) layer. We'll tell the model what input shape to expect and to use the predetermined weights from imagenet (Googles dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO89Hc_gazv-",
        "colab_type": "text"
      },
      "source": [
        "Let's work with the pretrained models and learn how to freeze layers or let them train again to be finetuned.\n",
        "In the following cell, implement a code that loads until the layer 280 of the InceptionV3 network and freeze all the previous layers. By comparing the summary of models you can see the differences between the number of trainable parameters in each models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMAoFbZnbnzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "base_model = InceptionV3(include_top=True, weights='imagenet')\n",
        "base_model.summary()\n",
        "\n",
        "# Name of a new model with freezed layers = EncoderUpToALayer\n",
        "########################################\n",
        "#     Put your implementation here     #\n",
        "########################################\n",
        "\n",
        "EncoderUpToALayer.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzqCkIog_YIa",
        "colab_type": "text"
      },
      "source": [
        "Now we are familiar with pretrained networks and how to customize them according to our needs. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2nxy4f9rp4J",
        "colab_type": "text"
      },
      "source": [
        "In the following cells you should use **VGG19** as your base model and then add some dense layers to make an improved model instead of simple CNN you designed.\n",
        "\n",
        "Again in this part you may face with a \"session crashed\" message. So solve the each phase of this assignment in separate session to prevent from this issue.\n",
        "* This link may help you:\n",
        "https://docs.w3cub.com/tensorflow~python/tf/keras/applications/vgg19/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azPGJyUZfnw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg19 import VGG19\n",
        "\n",
        "def Improved_Model():\n",
        "\n",
        "  ########################################\n",
        "  #     Put your implementation here     #\n",
        "  ########################################\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP-dMEme6GAs",
        "colab_type": "text"
      },
      "source": [
        "Train the Improved_Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6ErZt4jftXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard2 = TensorBoard(log_dir=f\"logs2/{time.time()}\", histogram_freq=1)\n",
        "IMPV_Model = Improved_Model()\n",
        "IMPV_Model.summary()\n",
        "\n",
        "IMPV_Model_history = IMPV_Model.fit(images,\n",
        "    labels, batch_size=64, epochs=9, validation_data=(images_test, labels_test), shuffle=True, callbacks=[tensorboard2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc8Zv7TB6Ylh",
        "colab_type": "text"
      },
      "source": [
        "It's time to call the visualization function and investigate the procedure of training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rym58n2gaCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_loss_and_acc(IMPV_Model_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaEJd9js6lWW",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model. After running the next cell, you will find out how the model classifies images better than before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_yQ3DS6xblF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = IMPV_Model.predict(images_test)\n",
        "# Maybe you need to run some of previous cells for defining and using variables\n",
        "ROWS = 5\n",
        "COLUMNS = 5\n",
        "fig, ax = plt.subplots(ROWS,COLUMNS, figsize=(18,18))\n",
        "for row in range(ROWS):\n",
        "    for column in range(COLUMNS):\n",
        "        imgIndex = random.randint(0, len(images_test))\n",
        "        image = images_test[imgIndex]\n",
        "        image = image.reshape(96,96,3)\n",
        "        ax[row,column].imshow(image,cmap=plt.cm.binary)\n",
        "        ax[row, column].set_title(class_names[np.argmax(predictions[imgIndex])], fontSize=10)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADtqyFdEzUyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "algo_score = IMPV_Model.evaluate(images_test, labels_test)[1]\n",
        "print(algo_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNxC_0J-6pjZ",
        "colab_type": "text"
      },
      "source": [
        "You should be getting an accuracy of about 70%. You can see the power of transfer learning. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd1N4-UP0r3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remember to run this cell after each time you update the model, \n",
        "# this is a deliverable item of your assignemnt\n",
        "IMPV_Model.save(str(ASSIGNMENT_PATH / 'Animals_Image_classification_Transfer.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLoPVwS619eI",
        "colab_type": "text"
      },
      "source": [
        "## Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiXsuWk82CRG",
        "colab_type": "text"
      },
      "source": [
        "Now we want to figure out how our model classifies images, what the layers learn, and with what features they can recognize the content of an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dulAFiMU2EyA",
        "colab_type": "text"
      },
      "source": [
        "So we need to examine the Convnets or Filters in more detail and understand what distinctive features are in their sight. \n",
        "\n",
        "In fact, if we want to delve deeper in CNN models, we should visualize the effect of different filters on a single image. Another important subject is that these layers make a decision by looking at some parts of an image.\n",
        "\n",
        "Let's break through these challenges.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xztBJ-Sy2HNO",
        "colab_type": "text"
      },
      "source": [
        "In next cell we want to look at the output of CNN model's intermediate layers. By doing so, we are able to learn more about the working of these layers.\n",
        "In short, looking at the outputs of our model's convolution and their corresponding maxpooling layers allows us to understand our trained model and the effect of the layers, when provided with one image from test set.\n",
        "\n",
        "So, for completing this part you need to make a list of IMPV_Model's layers and then construct a new model with input as same as the input of IMPV_Model and the output should be the different layers to show us the result of passing a single image through the filters. \n",
        "\n",
        "These links may help you about the structure: \n",
        "* [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://books.google.com/books?id=HHetDwAAQBAJ&pg=PA312&lpg=PA312&dq=can+we+give+a+list+as+a+ouput+of+a+model+in+keras&source=bl&ots=0Kvn2rhjMo&sig=ACfU3U2_HHi5p0HeVmGPYXw74dokz0rO6g&hl=en&sa=X&ved=2ahUKEwjtgfqE17jpAhWIfMAKHVVoAR8Q6AEwCXoECAkQAQ#v=onepage&q=can%20we%20give%20a%20list%20as%20a%20ouput%20of%20a%20model%20in%20keras&f=false)   \n",
        "* [Keras](https://keras.io/api/models/model/)\n",
        "\n",
        "Finally, we will have a list of different outputs for each of the desired filters and we can plot them. Check your code with predicting one test image. You need to customize the shape of your test image for prediction.  \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTT8He012OR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################\n",
        "#     Put your implementation here     #\n",
        "########################################\n",
        "\n",
        "DiffOutputs = ActivationModel.predict(test_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln4wOEWt2LTq",
        "colab_type": "text"
      },
      "source": [
        "Let's check the implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cyEZIiQ2Wh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert DiffOutputs[1].shape == (1, 96, 96, 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TIJlDcf2Xab",
        "colab_type": "text"
      },
      "source": [
        "If we take a look at the different images from Convolution filters, it is pretty clear to see how different filters in layers are trying to activate various parts of an image. By visualizing the output from different convolutional layers, the most crucial thing that we will notice is that the layers which are deeper in the network show us more specific features, while the earlier layers tend to visualize general patterns like edges, texture, background etc. In fact, when we use Transfer Learning and train some part of a pre-trained network (pre-trained on a different and big dataset, like ImageNet) on a completely different dataset, we will use the knowledge of earlier layers and force the model to update the weight of final layers. \n",
        "\n",
        "The general idea is to freeze the weights of earlier layers, because they will learn the general features, and we should only train the weights of deeper layers because these are the layers which are actually recognizing our objects in images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYbtkftd2ckG",
        "colab_type": "text"
      },
      "source": [
        "In the next part you will see the effect of Conv2d and MaxPooling layers in different depth of the model and understand the concept of mentioned points above. \n",
        "\n",
        "For completing the following cell, you should just write a simple code to get the **size** and the number of rows as a **n_rows**. You can do this with the use of each one of the filters you can get from the **DiffOutputs**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYmX1bte2e5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LayerNames = ['block1_conv2d_1', 'block1_pool_1', 'block3_conv2d_3', 'block3_pool_1']\n",
        "ActivList = [DiffOutputs[1], DiffOutputs[3], DiffOutputs[9], DiffOutputs[11]]\n",
        "\n",
        "NumOfImagesPerRow = 16\n",
        "\n",
        "for layer_name, layer_activation in zip(LayerNames, ActivList):\n",
        "  ########################################\n",
        "  #     Put your implementation here     #\n",
        "  ########################################\n",
        "  display_grid = np.zeros((size * n_rows, NumOfImagesPerRow * size)) \n",
        "  if layer_name == 'block1_conv2d_1' or layer_name == 'block1_pool_1':\n",
        "    assert n_rows == 4\n",
        "\n",
        "  if layer_name == 'block3_conv2d_3' or layer_name == 'block3_pool_1':\n",
        "    assert n_rows == 16\n",
        "\n",
        "  for col in range(n_rows):\n",
        "    for row in range(NumOfImagesPerRow):\n",
        "      channel_image = layer_activation[0, :, :, col * NumOfImagesPerRow + row]\n",
        "      channel_image -= channel_image.mean()\n",
        "      channel_image /= channel_image.std()\n",
        "      channel_image *= 64\n",
        "      channel_image += 128\n",
        "      channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "      display_grid[col * size : (col + 1) * size, row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "  scale = 1 / size\n",
        "  plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
        "  plt.title(layer_name)\n",
        "  plt.grid(False)\n",
        "  plt.imshow(display_grid, aspect='auto')\n",
        "  plt.savefig(layer_name+\"_grid.jpg\", bbox_inches='tight')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5KeaVpKQoLh",
        "colab_type": "text"
      },
      "source": [
        "### Class Activation Mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_aNBtvYMg6C",
        "colab_type": "text"
      },
      "source": [
        "In this section, you'll learn about Class Activation Mapping (CAM) and implement it using keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Xcynesv658",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YcbNlzOOFQx",
        "colab_type": "text"
      },
      "source": [
        "CAM was introduced in [this paper](http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf) and is a technique for demonstrating where in an image a network pays the most attention to when making a prediction! <br>\n",
        "To implement CAM, you have to use a Global Average Pooling (GAP) layer instead of the fully connected layers conventionaly used after convolution and pooling layers. So in Keras, instead of using a Flatten layer followed by some Dense layers, you should use a GlobalAveragePooling layer.<br>\n",
        "![CAM](https://github.com/iust-deep-learning/982/raw/master/static_files/assignments/asg03_assets/cam.PNG) <br>\n",
        "Let's go over the steps to implement CAM:\n",
        "- As you can see in the picture, you should first get the weights w1, w2, ... . These weights are basically the weights connecting the output of the GAP layer to the output neuron of the class whose activation map you want to create! \n",
        "- Next, you should use these weights to calculate a weighted average of the output feature maps of the convolution layers. The number of feature maps depends on the number of filters of the last convolution layer of the network. In this part of the assignment you should use VGG16, so we have 512 feature maps in the output of the last convolution layer. The final class activation map is the weighted average of these 512 feature maps! <br>\n",
        "\n",
        "Check out the paper for an in-depth explanation of this method. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYhvJ1-fT-pc",
        "colab_type": "text"
      },
      "source": [
        "Now let's load VGG16. For this part, we only want the last convolution layer of the VGG16 (__'block5_conv3'__) to be trainable so you should write a code in the cell below to make this layer the only trainable layer of VGG16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uY5vd2cwTBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "vgg16 = tf.keras.applications.VGG16(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        ")\n",
        "\n",
        "\n",
        "########################################\n",
        "#     Put your implementation here     #\n",
        "########################################\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66E2E_1DVEHd",
        "colab_type": "text"
      },
      "source": [
        "We'll be using the Cats vs Dogs dataset for this part which is made up of more than 23000 images of dogs and cats. We use TensorFlow Datasets to load this dataset. There a more datasets in the [TensorFlow website](https://www.tensorflow.org/datasets/catalog/overview), you can check them out if you want to make activation maps for a different dataset!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su78qBRC6U1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "### load the dataset using tensorflow_datasets\n",
        "(train_raw, test_raw), info = tfds.load('cats_vs_dogs',split=['train[:80%]', 'train[80%:]'],  with_info=True, as_supervised=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYehnIoa6rbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "\n",
        "### show the first three images\n",
        "for image, label in train_raw.take(3):\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "\n",
        "### resizing and preprocessing the images\n",
        "IMAGE_SIZE = 250\n",
        "def pre_process_image(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = image / 255.0\n",
        "  image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0S19dHp9vbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### shuffling, setting the batch size and applying the preprocessing and resizing to the images\n",
        "BATCH_SIZE = 50\n",
        "train = train_raw.map(pre_process_image).shuffle(1000).repeat().batch(BATCH_SIZE)\n",
        "test = test_raw.map(pre_process_image).repeat().batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_oAIfFqWA3e",
        "colab_type": "text"
      },
      "source": [
        "Now use VGG16 and a GAP layer to create an image classifier for the dogs and cats dataset! <br>\n",
        "__Instead of using a Dense with 1 unit and a sigmoid activation, use a Dense with 2 uints and a softmax activation so each class has its own set of weights and heatmaps are properly portrayed for each class__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIzrfTFyyrlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################\n",
        "#     Put your implementation here     #\n",
        "########################################\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUACDJtxyt4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train, epochs=4, steps_per_epoch = (23262)*0.8//BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5slDPM9Rvqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(test, steps=(23262)*0.2//BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-V8VcZgXbVI",
        "colab_type": "text"
      },
      "source": [
        "Now implement the ___get_heatmap___ function in the cell below. This function recieves an image as input and outputs a heatmap (activation map) for the class with the highest probability. Note that you'll need the output feature maps of the VGG16 in your model to implement this function. You can make new models or functions above the ___get_heatmap___ function if you need!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBydQHf_035h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################\n",
        "#     Put your implementation here     #\n",
        "########################################\n",
        "\n",
        "\n",
        "def get_heatmap(x):\n",
        "  \n",
        "  \"\"\" \n",
        "  Args:\n",
        "    x: A numpy array of shape (IMAGE_SIZE, IMAGE_SIZE, 3) which is an image\n",
        "    \n",
        "  Returns:\n",
        "    A numpy of shape (FM, FM) where FM is the size of the output feature map of the last conv layer of the network\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  ########################################\n",
        "  #     Put your implementation here     #\n",
        "  ########################################\n",
        "  return hmap\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPG8iqD6a8pO",
        "colab_type": "text"
      },
      "source": [
        "Now test your implementation using the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NlB6zVrHGiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "test1by1 = test_raw.map(pre_process_image).shuffle(1000).repeat().batch(1)\n",
        "ncols, nrows = 3, 3\n",
        "coords = [(i, j) for i in range(ncols) for j in range(nrows)]\n",
        "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(nrows*5,ncols*5))\n",
        "for x, y in test1by1.take(nrows*ncols):\n",
        "  img_idx = 0\n",
        "  img = x.numpy()[img_idx]\n",
        "  \n",
        "  heatmap = get_heatmap(img)\n",
        "  heatmap = 1-((heatmap - np.min(heatmap))/(np.max(heatmap)-np.min(heatmap)))\n",
        "  heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        " \n",
        "  heatmap = np.uint8(255*heatmap)\n",
        "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "  \n",
        "  heat_img = (heatmap/255)*0.6 + img\n",
        "  coord = coords.pop()\n",
        "  heat_img = np.clip(heat_img, 0, 1)\n",
        "  ax[coord[0], coord[1]].imshow(heat_img)\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSscYASJ7BI5",
        "colab_type": "text"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmV0ywSq7Bo4",
        "colab_type": "text"
      },
      "source": [
        "Congratulations! You finished the assignment & you're ready to submit your work. Please follow the instructions:\n",
        "\n",
        "1. Check and review your answers. Make sure all of the cell outputs are what you want. \n",
        "2. Select File > Save.\n",
        "3. Run **Make Submission** cell, It may take several minutes and it may ask you for your credential.\n",
        "4. Run **Download Submission** cell to obtain your submission as a zip file.\n",
        "5. Grab the downloaded file (`dl_asg03__xx__xx.zip`) and upload it via https://forms.gle/xeBPAep5Sz7WvpN29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8CyhvxK7MxQ",
        "colab_type": "text"
      },
      "source": [
        "## Make Submission (Run the cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqwARa3B7COc",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "! pip install -U --quiet PyDrive > /dev/null\n",
        "! wget -q https://github.com/github/hub/releases/download/v2.10.0/hub-linux-amd64-2.10.0.tgz \n",
        "  \n",
        "import os\n",
        "import time\n",
        "import yaml\n",
        "import json\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import Javascript\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "asg_name = 'Assignment3'\n",
        "script_save = '''\n",
        "require([\"base/js/namespace\"],function(Jupyter) {\n",
        "    Jupyter.notebook.save_checkpoint();\n",
        "});\n",
        "'''\n",
        "repo_name = 'iust-deep-learning-assignments'\n",
        "submission_file_name = 'dl_asg03__%s__%s.zip'%(student_id, student_name.lower().replace(' ',  '_'))\n",
        "course_url = 'https://iust-deep-learning.github.io/982/'\n",
        "\n",
        "! tar xf hub-linux-amd64-2.10.0.tgz\n",
        "! cd hub-linux-amd64-2.10.0/ && chmod a+x install && ./install\n",
        "! hub config --global hub.protocol https\n",
        "! hub config --global user.email \"$Your_Github_account_Email\"\n",
        "! hub config --global user.name \"$student_name\"\n",
        "! hub api -X GET /user\n",
        "! hub api -X GET /user > user_info.json\n",
        "! hub api -F affiliation=owner -X GET /user/repos > repos.json\n",
        "\n",
        "user_info = json.load(open('user_info.json'))\n",
        "repos = json.load(open('repos.json'))\n",
        "repo_names = [r['name'] for r in repos]\n",
        "has_repository = repo_name in repo_names\n",
        "if not has_repository:\n",
        "  get_ipython().system_raw('! hub api -X POST -F name=%s /user/repos homepage=\"%s\" > repo_info.json' % (repo_name, course_url))\n",
        "  repo_info = json.load(open('repo_info.json')) \n",
        "  repo_url = repo_info['clone_url']\n",
        "else:\n",
        "  username = user_info['login']\n",
        "  ! hub api -F homepage=\"$course_url\" -X PATCH /repos/$username/$repo_name\n",
        "  for r in repos:\n",
        "    if r['name'] == repo_name:\n",
        "      repo_url = r['clone_url']\n",
        "  \n",
        "stream = open(\"/root/.config/hub\", \"r\")\n",
        "token = list(yaml.load_all(stream))[0]['github.com'][0]['oauth_token']\n",
        "repo_url_with_token = 'https://'+token+\"@\" +repo_url.split('https://')[1]\n",
        "\n",
        "! git clone \"$repo_url_with_token\"\n",
        "! cp -r \"$ASSIGNMENT_PATH\" \"$repo_name\"/\n",
        "! cd \"$repo_name\" && git add -A\n",
        "! cd \"$repo_name\" && git commit -m \"Add assignment 3 results\"\n",
        "! cd \"$repo_name\" && git push -u origin master\n",
        "\n",
        "sub_info = {\n",
        "    'student_id': student_id,\n",
        "    'student_name': student_name, \n",
        "    'repo_url': repo_url,\n",
        "    'asg_dir_contents': os.listdir(str(ASSIGNMENT_PATH)),\n",
        "    'datetime': str(time.time()),\n",
        "    'asg_name': asg_name\n",
        "}\n",
        "json.dump(sub_info, open('info.json', 'w'))\n",
        "\n",
        "Javascript(script_save)\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "file_id = drive.ListFile({'q':\"title='%s.ipynb'\"%asg_name}).GetList()[0]['id']\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('%s.ipynb'%asg_name) \n",
        "\n",
        "! jupyter nbconvert --to script \"$asg_name\".ipynb > /dev/null\n",
        "! jupyter nbconvert --to html \"$asg_name\".ipynb > /dev/null\n",
        "! zip \"$submission_file_name\" \"$asg_name\".ipynb \"$asg_name\".html \"$asg_name\".txt info.json > /dev/null\n",
        "\n",
        "print(\"##########################################\")\n",
        "print(\"Done! Submisson created, Please download using the bellow cell!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRR-JxHEXCBL",
        "colab_type": "text"
      },
      "source": [
        "## Download Submission (Run the cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2PjpuR0V581",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "files.download(submission_file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9jGMA0FW9td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}